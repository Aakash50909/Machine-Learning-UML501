{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 12883067,
          "sourceType": "datasetVersion",
          "datasetId": 8150643
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-27T06:32:46.767551Z",
          "iopub.execute_input": "2025-08-27T06:32:46.767834Z",
          "iopub.status.idle": "2025-08-27T06:32:49.493620Z",
          "shell.execute_reply.started": "2025-08-27T06:32:46.767805Z",
          "shell.execute_reply": "2025-08-27T06:32:49.492530Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv(\"/kaggle/input/usa-housing/USA_Housing (1).csv\")\nprint(\"Dataset shape:\", df.shape)\nprint(df.describe())\nprint(df.head())",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-27T06:39:08.126475Z",
          "iopub.execute_input": "2025-08-27T06:39:08.126795Z",
          "iopub.status.idle": "2025-08-27T06:39:08.162083Z",
          "shell.execute_reply.started": "2025-08-27T06:39:08.126771Z",
          "shell.execute_reply": "2025-08-27T06:39:08.161224Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split, KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import r2_score\nimport warnings\nwarnings.filterwarnings('ignore')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "print(\"QUESTION 1: 5-Fold Cross Validation with Least Squares\")\nprint(\"=\"*60)\n\nX = df.drop('Price', axis=1)\ny = df['Price'].values\n\nprint(f\"Input features shape: {X.shape}\")\nprint(f\"Output variable shape: {y.shape}\")\nprint(f\"Feature names: {list(X.columns)}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "scaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nprint(\"Features scaled using StandardScaler\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "kf = KFold(n_splits=5, shuffle=True, random_state=42)\nbeta_matrices = []\nr2_scores = []\nfold_results = []\n\nprint(\"5-Fold Cross Validation Results:\")\nprint(\"-\" * 50)\n\nfor fold, (train_index, test_index) in enumerate(kf.split(X_scaled), 1):\n    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    \n    X_train_intercept = np.hstack([np.ones((X_train.shape[0], 1)), X_train])\n    X_test_intercept = np.hstack([np.ones((X_test.shape[0], 1)), X_test])\n    \n    beta = np.linalg.inv(X_train_intercept.T @ X_train_intercept) @ X_train_intercept.T @ y_train\n    beta_matrices.append(beta)\n    \n    y_pred = X_test_intercept @ beta\n    r2 = r2_score(y_test, y_pred)\n    r2_scores.append(r2)\n    \n    fold_results.append({\n        'fold': fold,\n        'beta': beta,\n        'r2_score': r2,\n        'train_size': len(X_train),\n        'test_size': len(X_test)\n    })\n    \n    print(f\"Fold {fold}: R2 Score = {r2:.6f}, Train size = {len(X_train)}, Test size = {len(X_test)}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "best_fold_idx = np.argmax(r2_scores)\nbest_beta = beta_matrices[best_fold_idx]\nbest_r2 = r2_scores[best_fold_idx]\n\nprint(f\"Best fold: {best_fold_idx + 1} with R2 score: {best_r2:.6f}\")\nprint(f\"Average R2 score across all folds: {np.mean(r2_scores):.6f}\")\nprint(f\"Standard deviation of R2 scores: {np.std(r2_scores):.6f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "print(\"Final Model Training (70% train, 30% test)\")\nprint(\"-\"*50)\n\nX_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n    X_scaled, y, test_size=0.3, random_state=42\n)\n\nX_train_final_intercept = np.hstack([np.ones((X_train_final.shape[0], 1)), X_train_final])\nX_test_final_intercept = np.hstack([np.ones((X_test_final.shape[0], 1)), X_test_final])\n\nfinal_beta = np.linalg.inv(X_train_final_intercept.T @ X_train_final_intercept) @ X_train_final_intercept.T @ y_train_final\nfinal_predictions = X_test_final_intercept @ final_beta\nfinal_r2 = r2_score(y_test_final, final_predictions)\n\nprint(f\"Final model R2 score on 30% test data: {final_r2:.6f}\")\nprint(f\"Training set size: {len(X_train_final)} (70%)\")\nprint(f\"Test set size: {len(X_test_final)} (30%)\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "print(\"\\nQUESTION 2: Validation Set Approach with Gradient Descent\")\nprint(\"=\"*60)\n\nX_temp, X_test_q2, y_temp, y_test_q2 = train_test_split(\n    X_scaled, y, test_size=0.3, random_state=42\n)\nX_train_q2, X_val_q2, y_train_q2, y_val_q2 = train_test_split(\n    X_temp, y_temp, test_size=0.2, random_state=42\n)\n\nprint(f\"Training set size: {len(X_train_q2)} ({len(X_train_q2)/len(X_scaled)*100:.0f}%)\")\nprint(f\"Validation set size: {len(X_val_q2)} ({len(X_val_q2)/len(X_scaled)*100:.0f}%)\")\nprint(f\"Test set size: {len(X_test_q2)} ({len(X_test_q2)/len(X_scaled)*100:.0f}%)\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "def gradient_descent_regression(X, y, learning_rate, iterations):\n    n_features = X.shape[1]\n    beta = np.zeros(n_features)\n    intercept = 0\n    m = len(y)\n    \n    for i in range(iterations):\n        y_pred = X.dot(beta) + intercept\n        dw = (1/m) * X.T.dot(y_pred - y)\n        db = (1/m) * np.sum(y_pred - y)\n        beta -= learning_rate * dw\n        intercept -= learning_rate * db\n    \n    return beta, intercept",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "learning_rates = [0.001, 0.01, 0.1, 1]\nresults_q2 = []\n\nprint(\"Testing different learning rates:\")\nprint(\"-\" * 40)\n\nfor lr in learning_rates:\n    beta, intercept = gradient_descent_regression(\n        X_train_q2, y_train_q2, lr, 1000\n    )\n    \n    val_pred = X_val_q2.dot(beta) + intercept\n    val_r2 = r2_score(y_val_q2, val_pred)\n    \n    test_pred = X_test_q2.dot(beta) + intercept\n    test_r2 = r2_score(y_test_q2, test_pred)\n    \n    results_q2.append({\n        'learning_rate': lr,\n        'beta': beta,\n        'intercept': intercept,\n        'val_r2': val_r2,\n        'test_r2': test_r2\n    })\n    \n    print(f\"LR = {lr:>5}: Val R2 = {val_r2:.4f}, Test R2 = {test_r2:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "best_lr_result = max(results_q2, key=lambda x: x['val_r2'])\nprint(f\"Best learning rate: {best_lr_result['learning_rate']}\")\nprint(f\"Best validation R2: {best_lr_result['val_r2']:.4f}\")\nprint(f\"Test R2 with best model: {best_lr_result['test_r2']:.4f}\")\n\nprint(\"\\nANALYSIS COMPLETE\")\nprint(\"=\"*50)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}